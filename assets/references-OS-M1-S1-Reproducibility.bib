@article{abele-brehmWerSollProfessur2016,
  title = {Wer Soll Die {{Professur}} Bekommen?},
  author = {{Abele-Brehm}, Andrea E. and B{\"u}hner, Markus},
  year = 2016,
  journal = {Psychologische Rundschau},
  volume = {67},
  number = {4},
  pages = {250--261},
  publisher = {Hogrefe Verlag},
  issn = {0033-3042},
  doi = {10.1026/0033-3042/a000335},
  urldate = {2025-10-30},
  abstract = {Zusammenfassung. Die Entwicklung einer Wissenschaft ist abh{\"a}ngig von den Personen, die sie tragen. Der Auswahl geeigneter Personen in Berufungsverfahren auf Professuren kommt deshalb eine besondere Bedeutung zu. Die vorliegende Studie besch{\"a}ftigt sich erstmals damit, wie Kolleginnen und Kollegen der Psychologie Berufungsverfahren beurteilen; wie wichtig sie verschiedene Indikatoren f{\"u}r die Eignung auf eine Professur einsch{\"a}tzen; wie hoch die Diskrepanz zwischen gew{\"u}nschter und tats{\"a}chlicher Relevanz dieser Indikatoren ist; sowie wie sie zu verschiedenen Ausgestaltungsm{\"o}glichkeiten von Berufungsverfahren stehen. Es wurden 3.784~Mitglieder der DGPs angeschrieben, um an einer online Befragung teilzunehmen. N~=~1.453 Personen beantworteten zumindest einen Teil der Fragen. Die Ergebnisse zeigen, dass die Diskrepanzen zwischen Ist und Soll bei {\"u}berfachlichen Kompetenzen (Kommunikation, Kooperation, strategisches Denken) besonders gro{\ss} sind und dass die Befragten den Stellenwert quantitativer Forschungsleistungsindikatoren als zu hoch ansehen. Die Befragten bef{\"u}rworten den Einsatz strukturierter Interviews zur Erfassung {\"u}berfachlicher Kompetenzen, eine multi-methodale Messung der Forschungs- und Lehrleistung durch qualitative und quantitative Indikatoren sowie st{\"a}rker strukturierte Probelehrvortr{\"a}ge. M{\"o}gliche fachpolitische Konsequenzen dieser Befunde werden diskutiert.},
  keywords = {Berufungsverfahren,Eignungskriterien,hiring procedures for professors,indicators of suitability,quantitative and qualitative research performance,quantitative und qualitative Indikatoren der Forschungsleistung,social and management skills,soziale und Management Fertigkeiten},
  file = {C:\Users\Sarah von Grebmer\Zotero\storage\UXK4GL8S\Abele-Brehm and Bühner - 2016 - Wer soll die Professur bekommen.pdf}
}

@article{armitageRepeatedSignificanceTests1969,
  title = {Repeated Significance Tests on Accumulating Data},
  author = {Armitage, P. and McPherson, C. K. and Rowe, B. C.},
  year = 1969,
  journal = {Journal of the Royal Statistical Society: Series A (General)},
  volume = {132},
  number = {2},
  pages = {235--244},
  issn = {2397-2327},
  doi = {10.2307/2343787},
  urldate = {2025-10-30},
  abstract = {If significance tests at a fixed level are repeated at stages during the accumulation of data the probability of obtaining a significant result when the null hypothesis is true rises above the nominal significance level. Numerical results are presented for repeated tests on cumulative series of binomial, normal and exponential observations.},
  copyright = {{\copyright} 1969 The Authors},
  langid = {english},
  file = {C:\Users\Sarah von Grebmer\Zotero\storage\SG73L9N6\Armitage et al. - 1969 - Repeated Significance Tests on Accumulating Data.pdf}
}

@article{craigUsingRetractedJournal2020,
  title = {Using Retracted Journal Articles in Psychology to Understand Research Misconduct in the Social Sciences: {{What}} Is to Be Done?},
  shorttitle = {Using Retracted Journal Articles in Psychology to Understand Research Misconduct in the Social Sciences},
  author = {Craig, Russell and Cox, Adam and Tourish, Dennis and Thorpe, Alistair},
  year = 2020,
  journal = {Research Policy},
  volume = {49},
  number = {4},
  pages = {103930},
  issn = {0048-7333},
  doi = {10.1016/j.respol.2020.103930},
  urldate = {2025-10-30},
  abstract = {This paper explores the nature and impact of research misconduct in psychology by analyzing 160 articles that were retracted from prominent scholarly journals between 1998 and 2017. We compare findings with recent studies of retracted papers in economics, and business and management, to profile practices that are likely to be problematic in cognate social science disciplines. In psychology, the principal reason for retraction was data fabrication. Retractions took longer to make, and generally were from higher ranked and more prestigious journals, than in the two cognate disciplines. We recommend that journal editors should be more forthcoming in the reasons they provide for article retractions. We also recommend that the discipline of psychology gives a greater priority to the publication of replication studies; initiates a debate about how to respond to failed replications; adopts a more critical attitude to the importance of attaining statistical significance; discourages p-hacking and Hypothesizing After Results are Known (HARKing); assesses the long-term effects of pre-registering research; and supports stronger procedures to attest to the authenticity of data in research papers. Our contribution locates these issues in the context of a growing crisis of confidence in the value of social science research. We also challenge individual researchers to reassert the primacy of disinterested academic inquiry above pressures that can lead to an erosion of scholarly integrity.},
  keywords = {Misconduct,Psychology,Replication,Research,Retractions},
  file = {C\:\\Users\\Sarah von Grebmer\\Zotero\\storage\\B29FXK85\\Craig et al. - 2020 - Using retracted journal articles in psychology to understand research misconduct in the social scien.pdf;C\:\\Users\\Sarah von Grebmer\\Zotero\\storage\\8TU9FL26\\S004873332030010X.html}
}

@article{fanelliPositiveResultsIncrease2010,
  title = {``{{Positive}}'' Results Increase down the Hierarchy of the Sciences},
  author = {Fanelli, Daniele},
  year = 2010,
  journal = {PLOS ONE},
  volume = {5},
  number = {4},
  pages = {e10068},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0010068},
  urldate = {2025-10-30},
  abstract = {The hypothesis of a Hierarchy of the Sciences with physical sciences at the top, social sciences at the bottom, and biological sciences in-between is nearly 200 years old. This order is intuitive and reflected in many features of academic life, but whether it reflects the ``hardness'' of scientific research---i.e., the extent to which research questions and results are determined by data and theories as opposed to non-cognitive factors---is controversial. This study analysed 2434 papers published in all disciplines and that declared to have tested a hypothesis. It was determined how many papers reported a ``positive'' (full or partial) or ``negative'' support for the tested hypothesis. If the hierarchy hypothesis is correct, then researchers in ``softer'' sciences should have fewer constraints to their conscious and unconscious biases, and therefore report more positive outcomes. Results confirmed the predictions at all levels considered: discipline, domain and methodology broadly defined. Controlling for observed differences between pure and applied disciplines, and between papers testing one or several hypotheses, the odds of reporting a positive result were around 5 times higher among papers in the disciplines of Psychology and Psychiatry and Economics and Business compared to Space Science, 2.3 times higher in the domain of social sciences compared to the physical sciences, and 3.4 times higher in studies applying behavioural and social methodologies on people compared to physical and chemical studies on non-biological material. In all comparisons, biological studies had intermediate values. These results suggest that the nature of hypotheses tested and the logical and methodological rigour employed to test them vary systematically across disciplines and fields, depending on the complexity of the subject matter and possibly other factors (e.g., a field's level of historical and/or intellectual development). On the other hand, these results support the scientific status of the social sciences against claims that they are completely subjective, by showing that, when they adopt a scientific approach to discovery, they differ from the natural sciences only by a matter of degree.},
  langid = {english},
  keywords = {Forecasting,Mental health and psychiatry,Physical sciences,Scientists,Social psychology,Social research,Social sciences,Sociology},
  file = {C:\Users\Sarah von Grebmer\Zotero\storage\V63DT94Q\Fanelli - 2010 - “Positive” Results Increase Down the Hierarchy of the Sciences.pdf}
}

@article{hoffmannMultiplicityAnalysisStrategies2021,
  title = {The Multiplicity of Analysis Strategies Jeopardizes Replicability: Lessons Learned across Disciplines},
  shorttitle = {The Multiplicity of Analysis Strategies Jeopardizes Replicability},
  author = {Hoffmann, Sabine and Sch{\"o}nbrodt, Felix and Elsas, Ralf and Wilson, Rory and Strasser, Ulrich and Boulesteix, Anne-Laure},
  year = 2021,
  journal = {Royal Society Open Science},
  volume = {8},
  number = {4},
  pages = {rsos.201925, 201925},
  issn = {2054-5703},
  doi = {10.1098/rsos.201925},
  urldate = {2025-10-30},
  abstract = {For a given research question, there are usually a large variety of possible analysis strategies acceptable according to the scientific standards of the field, and there are concerns that this multiplicity of analysis strategies plays an important role in the non-replicability of research findings. Here, we define a general framework on common sources of uncertainty arising in computational analyses that lead to this multiplicity, and apply this framework within an overview of approaches proposed across disciplines to address the issue. Armed with this framework, and a set of recommendations derived therefrom, researchers will be able to recognize strategies applicable to their field and use them to generate findings more likely to be replicated in future studies, ultimately improving the credibility of the scientific process.},
  langid = {english},
  file = {C:\Users\Sarah von Grebmer\Zotero\storage\8JY3KW63\Hoffmann et al. - 2021 - The multiplicity of analysis strategies jeopardizes replicability lessons learned across discipline.pdf}
}

@article{johnMeasuringPrevalenceQuestionable2012,
  title = {Measuring the Prevalence of Questionable Research Practices with Incentives for Truth Telling},
  author = {John, Leslie K. and Loewenstein, George and Prelec, Drazen},
  year = 2012,
  journal = {Psychological Science},
  volume = {23},
  number = {5},
  pages = {524--532},
  publisher = {SAGE Publications Inc},
  issn = {0956-7976},
  doi = {10.1177/0956797611430953},
  urldate = {2025-10-30},
  abstract = {Cases of clear scientific misconduct have received significant media attention recently, but less flagrantly questionable research practices may be more prevalent and, ultimately, more damaging to the academic enterprise. Using an anonymous elicitation format supplemented by incentives for honest reporting, we surveyed over 2,000 psychologists about their involvement in questionable research practices. The impact of truth-telling incentives on self-admissions of questionable research practices was positive, and this impact was greater for practices that respondents judged to be less defensible. Combining three different estimation methods, we found that the percentage of respondents who have engaged in questionable practices was surprisingly high. This finding suggests that some questionable practices may constitute the prevailing research norm.},
  langid = {english}
}

@article{oboyleChrysalisEffectHow2017,
  title = {The {{Chrysalis Effect}}: {{How}} Ugly Initial Results Metamorphosize into Beautiful Articles},
  shorttitle = {The {{Chrysalis Effect}}},
  author = {O'Boyle, Ernest Hugh and Banks, George Christopher and {Gonzalez-Mul{\'e}}, Erik},
  year = 2017,
  journal = {Journal of Management},
  volume = {43},
  number = {2},
  pages = {376--399},
  issn = {0149-2063, 1557-1211},
  doi = {10.1177/0149206314527133},
  urldate = {2025-10-30},
  abstract = {The issue of a published literature not representative of the population of research is most often discussed in terms of entire studies being suppressed. However, alternative sources of publication bias are questionable research practices (QRPs) that entail post hoc alterations of hypotheses to support data or post hoc alterations of data to support hypotheses. Using general strain theory as an explanatory framework, we outline the means, motives, and opportunities for researchers to better their chances of publication independent of rigor and relevance. We then assess the frequency of QRPs in management research by tracking differences between dissertations and their resulting journal publications. Our primary finding is that from dissertation to journal article, the ratio of supported to unsupported hypotheses more than doubled (0.82 to 1.00 versus 1.94 to 1.00). The rise in predictive accuracy resulted from the dropping of statistically nonsignificant hypotheses, the addition of statistically significant hypotheses, the reversing of predicted direction of hypotheses, and alterations to data. We conclude with recommendations to help mitigate the problem of an unrepresentative literature that we label the ``Chrysalis Effect.''},
  langid = {english},
  file = {C:\Users\Sarah von Grebmer\Zotero\storage\SZ8Q2RP5\O’Boyle et al. - 2017 - The Chrysalis Effect How Ugly Initial Results Metamorphosize Into Beautiful Articles.pdf}
}

@article{stefanBigLittleLies2023,
  title = {Big Little Lies: A Compendium and Simulation of {\emph{p}} -Hacking Strategies},
  shorttitle = {Big Little Lies},
  author = {Stefan, Angelika M. and Sch{\"o}nbrodt, Felix D.},
  year = 2023,
  journal = {Royal Society Open Science},
  volume = {10},
  number = {2},
  pages = {220346},
  issn = {2054-5703},
  doi = {10.1098/rsos.220346},
  urldate = {2025-10-30},
  abstract = {In many research fields, the widespread use of questionable research practices has jeopardized the credibility of scientific results. One of the most prominent questionable research practices is               p               -hacking. Typically,               p               -hacking is defined as a compound of strategies targeted at rendering non-significant hypothesis testing results significant. However, a comprehensive overview of these               p               -hacking strategies is missing, and current meta-scientific research often ignores the heterogeneity of strategies. Here, we compile a list of 12               p               -hacking strategies based on an extensive literature review, identify factors that control their level of severity, and demonstrate their impact on false-positive rates using simulation studies. We also use our simulation results to evaluate several approaches that have been proposed to mitigate the influence of questionable research practices. Our results show that investigating               p               -hacking at the level of strategies can provide a better understanding of the process of               p               -hacking, as well as a broader basis for developing effective countermeasures. By making our analyses available through a Shiny app and R package, we facilitate future meta-scientific research aimed at investigating the ramifications of               p               -hacking across multiple strategies, and we hope to start a broader discussion about different manifestations of               p               -hacking in practice.},
  langid = {english},
  file = {C:\Users\Sarah von Grebmer\Zotero\storage\I3HDH6Q2\Stefan and Schönbrodt - 2023 - Big little lies a compendium and simulation of p -hacking strategies.pdf}
}

@article{wassersteinASAStatementPValues2016,
  title = {The {{ASA}} Statement on P-{{Values}}: {{Context}}, Process, and Purpose},
  shorttitle = {The {{ASA Statement}} on P-{{Values}}},
  author = {Wasserstein, Ronald L. and Lazar, Nicole A.},
  year = 2016,
  journal = {The American Statistician},
  volume = {70},
  number = {2},
  pages = {129--133},
  publisher = {ASA Website},
  issn = {0003-1305},
  doi = {10.1080/00031305.2016.1154108},
  urldate = {2025-10-30},
  file = {C:\Users\Sarah von Grebmer\Zotero\storage\FMF2JKXL\Wasserstein and Lazar - 2016 - The ASA Statement on p-Values Context, Process, and Purpose.pdf}
}
